{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhutNTFK2S6I"
      },
      "source": [
        "## **Data Transformation**\n",
        "\n",
        "After cleaning, our data is accurate and consistent. But there’s one more challenge: machine learning models expect data to be in a specific numeric and scaled format.\n",
        "\n",
        "Data transformation is about making all features numerical, consistent, and ready for training a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulYojkDB2RbH"
      },
      "source": [
        "### **Encoding Categorical Values**\n",
        "\n",
        "**Why do we encode?**\n",
        "\n",
        "ML models only understand numbers — they can’t work with text directly. For example, in the column “workclass” with values like “Private”, “Self-Employed”, etc., we need to turn these into numbers.\n",
        "\n",
        "**How do we encode?**\n",
        "\n",
        "- Label Encoding → Each category gets a number (e.g., Private = 0, Self-Employed = 1). Best for ordered categories.\n",
        "\n",
        "- One-Hot Encoding → Creates new columns for each category (e.g., “Private”, “Self-Employed”), with 1s and 0s. Best for non-ordered categories.\n",
        "\n",
        "\n",
        "Encoding ensures categorical data can be included in the model without losing meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu5dpF1g426J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_adult = pd.read_csv('data/adult_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vZOp-7r4zu3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le=LabelEncoder()\n",
        "df_adult['workclass']=le.fit_transform(df_adult['workclass'])\n",
        "df_adult['education']=le.fit_transform(df_adult['education'])\n",
        "df_adult['marital-status']=le.fit_transform(df_adult['marital-status'])\n",
        "df_adult['relationship']=le.fit_transform(df_adult['relationship'])\n",
        "df_adult['race']=le.fit_transform(df_adult['race'])\n",
        "df_adult['sex']=le.fit_transform(df_adult['sex'])\n",
        "df_adult['native-country']=le.fit_transform(df_adult['native-country'])\n",
        "df_adult['class']=le.fit_transform(df_adult['class'])\n",
        "df_adult['occupation']=le.fit_transform(df_adult['occupation'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TdjXUeFt5CYp",
        "outputId": "64c62ad9-bdc3-4f19-bb17-ccb9ba36ccf7"
      },
      "outputs": [],
      "source": [
        "df_adult.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dP9XEQR5Mr0"
      },
      "source": [
        "Now we can see that the dataset is purely numerical , in a format it can be fed into any model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qNqRvur6wvI"
      },
      "source": [
        "### **Train Test Split**\n",
        "\n",
        "**Why split the data?**\n",
        "\n",
        "In machine learning, we want to train our model on one set of data and test it on a separate set to see how well it generalizes to new, unseen data. If we test on the same data we train on, the model might memorize patterns instead of learning them, giving misleadingly high accuracy.\n",
        "\n",
        "**What we are doing here:**\n",
        "\n",
        "- X_train and y_train → used to fit the model.\n",
        "\n",
        "- X_test and y_test → used to evaluate the model’s performance.\n",
        "\n",
        "We also stratify by the target so the class distribution stays consistent in both sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSNhvyaj7S0B"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_adult.drop('class', axis=1)  # Features\n",
        "y = df_adult['class']               # Target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNHyPZ5Y7bXf"
      },
      "source": [
        "Now that we have separate training and testing sets, we can safely apply **transformations** like scaling and normalization.\n",
        "These transformations will be fitted on the **training set only**, and then applied to the test set — this prevents the model from “seeing” test data during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h_7mZHp5NsU"
      },
      "source": [
        "### **Scaling and Normalization**\n",
        "Machine learning models work better when features are on a similar scale. If one feature (e.g., capital-gain) has values in the thousands, while another (e.g., education-num) ranges only from 1–16, the model may give more importance to the larger-scale feature—even if it’s not actually more important.\n",
        "\n",
        "To prevent this, we use scaling and normalization techniques.\n",
        "\n",
        "- Scaling → Rescales features to a specific range (e.g., 0–1).\n",
        "\n",
        "- Standardization → Centers features around mean = 0 and std = 1.\n",
        "\n",
        "- Normalization → Converts features to have unit norm (useful for distance-based algorithms).\n",
        "\n",
        "\n",
        "This can be done in multiple ways which we will see below:\n",
        "\n",
        "**Key point:**\n",
        "\n",
        "- Always fit the scaler/normalizer on the training data only.\n",
        "\n",
        "- Then apply the same transformation to the test data.\n",
        "\n",
        "- This avoids data leakage, ensuring your model doesn’t “peek” at the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVKu88PW5ntM"
      },
      "source": [
        "### **Method 1: Min- Max Normalization**\n",
        "\n",
        "Min-Max scaling compresses all feature values into a fixed range, usually 0 to 1.\n",
        "\n",
        "$$X' = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
        "\n",
        "**Useful when:**\n",
        "- Data has a known fixed boundary (e.g., percentages, pixel values in images).\n",
        "\n",
        "- Algorithms that rely on distances or gradients (e.g., KNN, neural networks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kkk-meWA6Kk7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "minmax = MinMaxScaler()\n",
        "X_train_minmax = minmax.fit_transform(X_train)\n",
        "X_test_minmax = minmax.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUiBhBCt8f8P"
      },
      "source": [
        "### **Method 2: Z- Score Normalization**\n",
        "Z-score standardization transforms the data into a standard normal distribution, meaning the values are shifted so that:\n",
        "\n",
        "Mean = 0\n",
        "\n",
        "Standard Deviation = 1\n",
        "\n",
        "$$X' = \\frac{X - \\mu}{ \\sigma }$$\n",
        "\n",
        "**Useful when:**\n",
        "\n",
        "- Data is roughly normally distributed (bell-shaped).\n",
        "\n",
        "- Algorithms assume Gaussian distribution (e.g., Logistic Regression, SVM, PCA).\n",
        "\n",
        "- Useful when features don’t have a clear upper/lower bound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2jcHFTw9dYk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "standard = StandardScaler()\n",
        "X_train_standard = standard.fit_transform(X_train)\n",
        "X_test_standard = standard.transform(X_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
