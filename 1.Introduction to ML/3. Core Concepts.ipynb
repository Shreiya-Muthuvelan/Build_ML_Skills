{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcca6980",
   "metadata": {},
   "source": [
    "## Core Machine Learning Concepts\n",
    "\n",
    "There are a few things that we need to understand before learning about ML algorithms. We will see that below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07375c",
   "metadata": {},
   "source": [
    "### **1. Features and Labels**\n",
    "\n",
    "In machine learning, you can think of features as the questions you ask and the label as the answer you're trying to predict.\n",
    "\n",
    " For example, if you're trying to predict a house's price, the features would be its size, number of bedrooms, and location, while the label would be the actual price. A model learns the relationship between the features and the label from the data you provide.\n",
    "\n",
    "\n",
    "<img src=\"https://developers.google.com/static/machine-learning/intro-to-ml/images/labeled_example.png\" width=\"800\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9228330",
   "metadata": {},
   "source": [
    "### **2. Overfitting vs. Underfitting**\n",
    "\n",
    "These two concepts describe common problems with a model's performance.\n",
    "\n",
    "- Overfitting: An overfit model is like a student who memorizes every answer for a test without understanding the underlying concepts.  It learns the \"noise\" and random fluctuations in the training data too well. As a result, it performs exceptionally on the training data but fails to generalize and make accurate predictions on new, unseen data.\n",
    "\n",
    "- Underfitting: An underfit model is too simple to capture the essential patterns in the data. It's like a student who doesn't study enough and can't even answer the basic questions on a test.  It performs poorly on both the training and testing data because it hasn't learned the core relationship between the features and the label.\n",
    "\n",
    "The goal is to find a balanceâ€”a model that is complex enough to learn the patterns but not so complex that it starts learning the noise.\n",
    "\n",
    "<img src=\"https://miro.medium.com/0*9dMWQGuWz5SiiBw7\" width=\"800\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c60d67",
   "metadata": {},
   "source": [
    "### **3. Training and Testing Data**\n",
    "\n",
    "To ensure a model can generalize, we split our dataset into two parts:\n",
    "\n",
    "- **Training Data:** This is the bulk of your data, typically 70-80%, that the model uses to learn. It's the dataset the model \"sees\" and adjusts its internal parameters based on.\n",
    "\n",
    "- **Testing Data:** This is a separate, held-out portion of your data, typically 20-30%. The model has never seen this data before. After training is complete, we use the testing data to evaluate the model's performance on new examples, which gives us a reliable measure of how well it will perform in the real world."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
